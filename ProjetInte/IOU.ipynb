{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import (\n",
    "    core,\n",
    "    models,\n",
    "    denoise\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    ConcatDataset,\n",
    "    DataLoader\n",
    ")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "assert core.use_gpu() == 1, \"No GPU detected\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = denoise.CellposeDenoiseModel(gpu=1, model_type='cyto3', restore_type=\"denoise_cyto3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BBox:\n",
    "\tmin: np.ndarray\n",
    "\tmax: np.ndarray\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\t_min: np.ndarray,\n",
    "\t\t_max: np.ndarray\n",
    "\t):\n",
    "\t\tassert _min.shape == _max.shape, \"Both must have the same dimension\"\n",
    "\t\tself.min = _min\n",
    "\t\tself.max = _max\n",
    "\n",
    "\tdef __repr__(self) -> str:\n",
    "\t\treturn f\"BBox({self.min}; {self.max})\"\n",
    "\n",
    "\tdef intersect(self, bb):\n",
    "\t\tassert self.min.shape == bb.min.shape, \"Both must have the same dimension\"\n",
    "\n",
    "\t\treturn BBox(\n",
    "\t\t\t_min = np.array([self.min, bb.min]).max(axis=0),\n",
    "\t\t\t_max = np.array([self.max, bb.max]).min(axis=0)\n",
    "\t\t)\n",
    "\t\n",
    "\tdef union(self, bb):\n",
    "\t\tassert self.min.shape == bb.min.shape, \"Both must have the same dimension\"\n",
    "\n",
    "\t\treturn BBox(\n",
    "\t\t\t_min = np.array([self.min, bb.min]).min(axis=0),\n",
    "\t\t\t_max = np.array([self.max, bb.max]).max(axis=0)\n",
    "\t\t)\n",
    "\n",
    "\tdef IoU(self, bb) -> float:\n",
    "\t\ta_its = self.intersect(bb).area()\n",
    "\t\ta_bb = bb.area()\n",
    "\t\ta_self = self.area()\n",
    "\n",
    "\t\t# Area(A U B) = Area(A) + Area(B) - Area(A inter B)\n",
    "\t\treturn a_its / (a_bb + a_self - a_its)\n",
    "\n",
    "\tdef area(self) -> float:\n",
    "\t\treturn (self.max - self.min).prod()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MendeleyCategory:\n",
    "    supercategory: str\n",
    "    name: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MendeleyCategoryEntryCell:\n",
    "    category: MendeleyCategory\n",
    "    bbox: BBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MendeleyDatasetEntry:\n",
    "    width: int\n",
    "    height: int\n",
    "    filename: str\n",
    "\n",
    "    cells: list[MendeleyCategoryEntryCell]\n",
    "\n",
    "    def __init__(self, width: int, height: int, filename: str):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.filename = filename\n",
    "        self.cells = []\n",
    "    \n",
    "    def add_entry(self, entry: MendeleyCategoryEntryCell):\n",
    "        self.cells.append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MendeleyDataset(Dataset):\n",
    "    images_path: str\n",
    "    entries: list[MendeleyDatasetEntry]\n",
    "    categories: dict[int, MendeleyCategory]\n",
    "\n",
    "    def __init__(self, annotation_path: str, images_path: str):\n",
    "        self.images_path = images_path\n",
    "        with open(annotation_path) as af:\n",
    "            infos = json.load(af)\n",
    "            entries = {\n",
    "                img[\"id\"]: (\n",
    "                    MendeleyDatasetEntry(\n",
    "                        width = img[\"width\"],\n",
    "                        height = img[\"height\"],\n",
    "                        filename = img[\"file_name\"]\n",
    "                    )\n",
    "                ) for img in infos[\"images\"]\n",
    "            }\n",
    "            self.categories = {\n",
    "                cat[\"id\"]: (\n",
    "                    MendeleyCategory(\n",
    "                        name = cat[\"name\"],\n",
    "                        supercategory = cat[\"supercategory\"]\n",
    "                    )\n",
    "                ) for cat in infos[\"categories\"]\n",
    "            }\n",
    "            for anno in infos[\"annotations\"]:\n",
    "                top_left = np.array(anno[\"bbox\"][0:2])\n",
    "                size = np.array(anno[\"bbox\"][2:4])\n",
    "                bbox = BBox(\n",
    "                    top_left,\n",
    "                    top_left + size,\n",
    "                )\n",
    "                entries[anno[\"image_id\"]].add_entry(\n",
    "                    MendeleyCategoryEntryCell(\n",
    "                        category = self.categories[anno[\"category_id\"]],\n",
    "                        bbox = bbox\n",
    "                    )\n",
    "                )\n",
    "            self.entries = list(entries.values())\n",
    "    \n",
    "    def __getitem__(self,idx: int) -> Tuple[np.array, np.array, list[MendeleyCategoryEntryCell]]:\n",
    "        entry = self.entries[idx]\n",
    "        img = np.array(Image.open(\"{}/{}\".format(\n",
    "            self.images_path,\n",
    "            entry.filename\n",
    "        )))\n",
    "        real_mask = np.zeros(img.shape, dtype=bool)\n",
    "        for info in entry.cells:\n",
    "            real_mask[\n",
    "                int(info.bbox.min[1]): int(np.ceil(info.bbox.max[1])),\n",
    "                int(info.bbox.min[0]): int(np.ceil(info.bbox.max[0]))\n",
    "            ] = True\n",
    "        return img / 255., real_mask, entry.cells\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = MendeleyDataset(\"images/livecell_coco_test.json\", \"images/livecell_test_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, real_mask, infos = dt[1]\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.imshow(img)\n",
    "for info in infos:\n",
    "    ax.plot([info.bbox.min[0], info.bbox.max[0]], [info.bbox.min[1]]*2, color='red')\n",
    "    ax.plot([info.bbox.min[0], info.bbox.max[0]], [info.bbox.max[1]]*2, color='red')\n",
    "    ax.plot([info.bbox.min[0]]*2, [info.bbox.min[1], info.bbox.max[1]], color='red')\n",
    "    ax.plot([info.bbox.max[0]]*2, [info.bbox.min[1], info.bbox.max[1]], color='red')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, flows, styles, imgs_dn = model.eval(img, diameter=None, flow_threshold=None, channels=[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(~np.isin(masks, [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs_dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import utils\n",
    "\n",
    "plt.imshow(imgs_dn)\n",
    "outline = utils.outlines_list(masks)\n",
    "for o in outline:\n",
    "    plt.plot(o[:,0], o[:,1], color='red')\n",
    "for info in infos:\n",
    "    plt.plot([info.bbox.min[0], info.bbox.max[0]], [info.bbox.min[1]]*2, color='darkgreen')\n",
    "    plt.plot([info.bbox.min[0], info.bbox.max[0]], [info.bbox.max[1]]*2, color='darkgreen')\n",
    "    plt.plot([info.bbox.min[0]]*2, [info.bbox.min[1], info.bbox.max[1]], color='darkgreen')\n",
    "    plt.plot([info.bbox.max[0]]*2, [info.bbox.min[1], info.bbox.max[1]], color='darkgreen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(real_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.imshow(~real_mask & (~np.isin(masks, [0])))\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.imshow(real_mask & ~(~np.isin(masks, [0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc_prec(masks: np.array, real_mask: np.array) -> tuple[float, float]:\n",
    "\tmasks = np.isin(masks, [0])\n",
    "\treal_mask = np.isin(real_mask, [0])\n",
    "\n",
    "\ttot = masks.shape[0]*masks.shape[1]\n",
    "\tfp_plus_fn = np.count_nonzero(masks ^ real_mask)\n",
    "\ttp = np.count_nonzero(masks & real_mask)\n",
    "\tfp = np.count_nonzero(masks & ~real_mask)\n",
    "\n",
    "\taccuracy = 1 - fp_plus_fn / tot\n",
    "\tprecision = tp / (tp + fp)\n",
    "\n",
    "\treturn accuracy, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "def compute_accuracy_and_precision(filter_ = None) -> tuple[float, float]:\n",
    "\tdef running_ex(i):\n",
    "\t\tprint(f\"{i} / {len(dt)}\")\n",
    "\t\timg, real_mask, _ = dt[i]\n",
    "\t\tif filter_ is not None:\n",
    "\t\t\timg = filter_(img)\n",
    "\t\tmasks, flows, styles, imgs_dn = model.eval(img, diameter=None, flow_threshold=None, channels=[2,1])\n",
    "\t\t\n",
    "\t\treturn compute_acc_prec(masks, real_mask)\n",
    "\n",
    "\tpool = ThreadPool(16)\n",
    "\tacc_prec = pool.map(running_ex, range(len(dt)))\n",
    "\n",
    "\tsum_accuracy = sum(map(\n",
    "\t\tlambda x: x[0],\n",
    "\t\tacc_prec\n",
    "\t))\n",
    "\tsum_precision = sum(map(\n",
    "\t\tlambda x: x[1],\n",
    "\t\tacc_prec\n",
    "\t))\n",
    "\treturn (sum_accuracy / len(dt)), (sum_precision / len(dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "rng = np.random.default_rng()\n",
    "noise_level = np.arange(0., 0.3+0.01, 0.03)\n",
    "\n",
    "for noise in noise_level:\n",
    "\tprint(f\"Testing dataset with noise of {noise}\")\n",
    "\tdef img_filter(img: np.array) -> np.array:\n",
    "\t\tout = img + noise * rng.normal(size=img.shape)\n",
    "\t\treturn np.clip(out, 0., 1.)\n",
    "\t\n",
    "\toutput.append(compute_accuracy_and_precision(img_filter))\n",
    "output = np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(2, 1, 1)\n",
    "ax.plot(noise_level, output[:,0], label=f\"Accuracy with loc={0}\")\n",
    "ax.legend()\n",
    "ax = plt.subplot(2, 1, 2)\n",
    "ax.plot(noise_level, output[:,1], label=f\"Precision with loc={0}\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_poisson = []\n",
    "lam = 4.\n",
    "\n",
    "for noise in noise_level:\n",
    "\tprint(f\"Testing dataset with noise of {noise}\")\n",
    "\tdef img_filter(img: np.array) -> np.array:\n",
    "\t\tout = img + noise * rng.poisson(lam=lam, size=img.shape)\n",
    "\t\treturn np.clip(out, 0., 1.)\n",
    "\t\n",
    "\toutput_poisson.append(compute_accuracy_and_precision(img_filter))\n",
    "output_poisson = np.array(output_poisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(2, 1, 1)\n",
    "ax.plot(noise_level, output_poisson[:,0], label=f\"Accuracy with lam={lam}\")\n",
    "ax.legend()\n",
    "ax = plt.subplot(2, 1, 2)\n",
    "ax.plot(noise_level, output_poisson[:,1], label=f\"Precision with lam={lam}\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
